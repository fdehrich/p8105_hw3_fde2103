---
title: "Homework 3"
author: Fiona Ehrich
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)
library(p8105.datasets)

knitr::opts_chunk$set(
	fig.width = 6, 
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

```{r}
data("instacart")
```

This datasets contains `r nrow(instacart)` rows and `r ncol(instacart)` columns. Observations are the level of items in orders by user. There are user / order variables -- user ID, order ID, order day, and order hour. There are also item variables -- name, aisle, department, and some numeric codes. There are various aisles within a given department.

There are `r instacart %>% count(aisle) %>% nrow()` aisles. The table below shows that most items are from the following aisles: "fresh vegetables", "fresh fruits", and "packaged vegetables fruits".

```{r}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

Below is a plot that shows the number of items ordered in each aisle, limited to aisles with more than 10000 items ordered.

```{r}
instacart %>% 
	count(aisle) %>% 
	filter(n > 10000) %>% 
	mutate(
		aisle = factor(aisle),
		aisle = fct_reorder(aisle, n)
	) %>% 
	ggplot(aes(x = aisle, y = n)) + 
	geom_point() + 
	theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

Below is a table showing the three most popular items in each of the aisles "baking ingredients", "dog food care", "packaged vegetables fruits".

```{r}
instacart %>% 
	filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
	group_by(aisle) %>% 
	count(product_name) %>% 
	mutate(rank = min_rank(desc(n))) %>% 
	filter(rank < 4) %>% 
	arrange(aisle, rank) %>% 
	knitr::kable()
```

Below is a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week.

```{r message = FALSE, warning = FALSE}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  ) %>% 
  knitr::kable()
```

## Problem 2

Load, tidy, and otherwise wrangle the data.

```{r}
accel =
  read_csv(
    "./data/accel_data.csv",
    col_types = cols( # I am making sure these variables are in appropriate classes
      week = col_factor(),
      day_id = col_factor(),
      day = col_factor()
      )
    ) %>% 
  janitor::clean_names() %>% 
  pivot_longer( # Making the dataset more tidy
    activity_1:activity_1440,
    names_to = "minute",
    names_prefix = "activity_",
    names_transform = list(minute = as.numeric), # Making the minute variable numeric
    values_to = "activity",
    ) %>% 
  mutate(
    day = forcats::fct_relevel(day,c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")), # Putting the day of the week factors in a sensible order
    day_type = # Making a new variable to indicate whether weekend or weekday
      as.factor(
        ifelse(day == c("Saturday", "Sunday"), "weekend", "weekday")
        )
    )
```

The resulting dataset has `r nrow(accel)` rows and `r ncol(accel)` columns. The variables are: `r names(accel)`. This dataset is now tidier than it was originally; each activity observation now exists on its own row.

Now, I will aggregate across minutes to create a total activity for each day. Below is a table that displays the total activity for each day in chronological order (I sorted first by week and then by day of the week). I put this table into a "wider" format so it is easier to read.

```{r message = FALSE, warning = FALSE}
accel %>% 
  group_by(week, day) %>% 
  summarize(total_activity = sum(activity)) %>% 
  pivot_wider(
    names_from = day,
    values_from = total_activity) %>% 
  knitr::kable()
```

It is hard to see any particular trends from this table alone. Just for my own knowledge, I created a "longer" version of this table and sorted from highest to lowest total activity per day (below). I can see that the maximum total activity per day is 685910.00 and the minimum total activity per day is 1440.00 (and I can see how each day ranks in terms of total activity).

```{r message = FALSE, warning = FALSE}
accel %>% 
  group_by(week, day) %>% 
  summarize(total_activity = sum(activity)) %>% 
  arrange(desc(total_activity)) %>% 
  knitr::kable()
```

I am now making a plot that shows the 24-hour activity time courses for each day.

```{r}
accel %>% 
  ggplot(aes(x = minute, y = activity, color = day)) + 
  geom_smooth(se = FALSE) +
  labs(
    title = "24-Hour Activity Time Course by Day of the Week (Accelerometer Data)",
    x = "Minute of the Day",
    y = "Activity Count",
    color = "Day of the Week",
    caption = "Note: Minute 1 corresponds to midnight."
  )
```

From this plot, I can see that activity tends to be lower at night (presumably while the person wearing the accelerometer is resting or sleeping) and higher during the day. I also notice some peaks in activity on Sunday late mornings and on Friday evenings. I think that these peaks could correspond to some of this person's regular, weekly activities (for example, going out on the town on Friday nights!).